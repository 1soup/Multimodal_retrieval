{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4H70Mp-DIaPP"},"outputs":[],"source":["!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"markdown","source":["中文CLIP huggingface demo"],"metadata":{"id":"c1MBvfhyIRXL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3116,"status":"ok","timestamp":1710218434386,"user":{"displayName":"Thomasine Kaczka","userId":"06732724743998191518"},"user_tz":-480},"id":"RI86z8fdCoRX","outputId":"ee4e8ffd-81a2-46d3-98bd-1816ca1919d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.1047,  0.0269,  0.0761, -0.0248,  0.0007]], device='cuda:0')\n","[[0.946 0.    0.054 0.    0.   ]]\n"]}],"source":["from PIL import Image\n","import requests\n","import clip\n","import torch\n","from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","query_texts = [\"一只猫\", \"一只狗\",'两只猫', '两只老虎','一只老虎']  # 这里是输入文本的，可以随意替换。\n","# 加载Taiyi 中文 text encoder\n","text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\")\n","text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\").eval().to(device)\n","text = text_tokenizer(query_texts, return_tensors='pt', padding=True)['input_ids'].to(device)\n","\n","url = \"https://hbimg.huaban.com/e637198ad1a5a0b4347d1a21abdd4a6118bd5accb4a23-etvyBB_fw658\"  # 这里可以换成任意图片的url\n","image_path = \"/content/drive/MyDrive/picture_data/宠物猫_2.png\"\n","# 加载CLIP的image encoder\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", device=device)\n","# image = processor(images=Image.open(requests.get(url, stream=True).raw), return_tensors=\"pt\")\n","image = processor(images=(Image.open(image_path)), return_tensors=\"pt\").to(device)\n","\n","\n","with torch.no_grad():\n","    image_features = clip_model.get_image_features(**image)\n","    text_features = text_encoder(text).logits\n","    # 归一化\n","    image_features = image_features / image_features.norm(dim=1, keepdim=True)\n","    text_features = text_features / text_features.norm(dim=1, keepdim=True)\n","    # 计算余弦相似度 logit_scale是尺度系数\n","    logit_scale = clip_model.logit_scale.exp()\n","    logits_per_image = logit_scale * image_features @ text_features.t()\n","    similarity = image_features @ text_features.T\n","    print(similarity)\n","    logits_per_text = logits_per_image.t()\n","    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","    print(np.around(probs, 3))"]},{"cell_type":"markdown","source":["计算类别概率/相似度"],"metadata":{"id":"hgM9QGSVIt7s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-gV92AK4FU-"},"outputs":[],"source":["def predict(image, text):\n","    with torch.no_grad():\n","        image_features = clip_model.get_image_features(**image)\n","        text_features = text_encoder(text).logits\n","        # 归一化\n","        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n","        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n","        # 计算余弦相似度 logit_scale是尺度系数\n","        logit_scale = clip_model.logit_scale.exp()\n","        logits_per_image = logit_scale * image_features @ text_features.t()\n","        logits_per_text = logits_per_image.t()\n","        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","        return probs\n","\n","def cal_similarity(image, text):\n","    with torch.no_grad():\n","        image_features = clip_model.get_image_features(**image)\n","        text_features = text_encoder(text).logits\n","        # 归一化\n","        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n","        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n","        # 计算余弦相似度 logit_scale是尺度系数\n","        logit_scale = clip_model.logit_scale.exp()\n","        similarity = image_features @ text_features.t()\n","        # logits_per_text = logits_per_image.t()\n","        # probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","        return similarity.cpu().numpy()"]},{"cell_type":"markdown","source":["卡阈值（单类别+others）"],"metadata":{"id":"UwN94Fi6I7_5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":651049,"status":"ok","timestamp":1710234098914,"user":{"displayName":"Thomasine Kaczka","userId":"06732724743998191518"},"user_tz":-480},"id":"uwsKUUx-2-Pj","outputId":"be7055d9-82c0-4b38-fb5b-698e95aec7ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (2), or the `sep_token_id` (None), and your input is not padded.\n"]},{"output_type":"stream","name":"stdout","text":["Category: 宠物猫, Precision: 0.7866, Recall: 0.9950, F1 Score: 0.8786\n","Category: 番茄, Precision: 0.5587, Recall: 1.0000, F1 Score: 0.7168\n","Category: 剪纸, Precision: 0.8032, Recall: 1.0000, F1 Score: 0.8909\n","Category: 电脑, Precision: 0.6576, Recall: 0.9700, F1 Score: 0.7838\n","Category: 饺子, Precision: 0.4158, Recall: 1.0000, F1 Score: 0.5874\n","Average Precision: 0.6444, Average Recall: 0.9930, Average F1: 0.7715\n"]}],"source":["from PIL import Image\n","import requests\n","import clip\n","import torch\n","from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","import os\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\")\n","text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\").eval().to(device)\n","\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", device=device)\n","\n","# 定义类别和对应的图片命名规则\n","categories = [\"宠物猫\", \"番茄\", \"剪纸\", \"电脑\", \"饺子\"]\n","\n","# 初始化统计数据\n","stats = {category: {\"TP\": 0, \"FP\": 0, \"FN\": 0} for category in categories}\n","\n","# 图片文件夹路径\n","image_folder_path = \"/content/drive/MyDrive/picture_data\"\n","\n","# 设定阈值\n","threshold = 0.99\n","\n","# 初始化用于计算平均的变量\n","total_precision = 0\n","total_recall = 0\n","total_f1 = 0\n","\n","# 对每个类别分别计算precision和recall\n","for category in categories:\n","    # 初始化统计数据\n","    TP = 0\n","    FP = 0\n","    FN = 0\n","\n","    # 遍历图片\n","    for image_name in os.listdir(image_folder_path):\n","        if image_name.endswith(\".png\"):\n","            image_path = os.path.join(image_folder_path, image_name)\n","\n","            # 预处理图片\n","            image = processor(images=(Image.open(image_path)), return_tensors=\"pt\").to(device)\n","\n","            # 准备文本\n","            text_labels = [category, \"其他\"]\n","            # text = clip.tokenize(list(categories.keys()) + [\"others\"]).to(device)\n","            text = text_tokenizer(text_labels, return_tensors='pt', padding=True)['input_ids'].to(device)\n","\n","            # 进行预测\n","            probs = predict(image, text)\n","\n","            # 使用阈值判断类别\n","            is_positive_prediction = probs[0, 0] > threshold\n","            predicted_category = category if is_positive_prediction else \"others\"\n","\n","            # 判断真实类别\n","            actual_category = category if category in image_name else \"others\"\n","\n","            # 更新统计数据\n","            if predicted_category == actual_category and actual_category == category:\n","                TP += 1\n","            elif predicted_category == category and actual_category == \"others\":\n","                FP += 1\n","            elif actual_category == category and predicted_category == \"others\":\n","                FN += 1\n","\n","    # 计算Precision和Recall\n","    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n","    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","\n","    print(f\"Category: {category}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n","    total_precision += precision\n","    total_recall += recall\n","    total_f1 += f1_score\n","\n","# 计算并打印平均Precision和Recall\n","average_precision = total_precision / len(categories)\n","average_recall = total_recall / len(categories)\n","average_f1 = total_f1 / len(categories)\n","\n","print(f\"Average Precision: {average_precision:.4f}, Average Recall: {average_recall:.4f}, Average F1: {average_f1:.4f}\")"]},{"cell_type":"markdown","source":["卡阈值（单类别相似度）"],"metadata":{"id":"U_DTx1FxJPgF"}},{"cell_type":"code","source":["from PIL import Image\n","import requests\n","import clip\n","import torch\n","from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","import os\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\")\n","text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\").eval().to(device)\n","\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", device=device)\n","\n","# 定义类别和对应的图片命名规则\n","categories = [\"宠物猫\", \"番茄\", \"剪纸\", \"电脑\", \"饺子\"]\n","\n","# 初始化统计数据\n","stats = {category: {\"TP\": 0, \"FP\": 0, \"FN\": 0} for category in categories}\n","\n","# 图片文件夹路径\n","image_folder_path = \"/content/drive/MyDrive/picture_data\"\n","\n","# 设定阈值\n","threshold = 0.11\n","\n","# 初始化用于计算平均的变量\n","total_precision = 0\n","total_recall = 0\n","total_f1 = 0\n","\n","# 对每个类别分别计算precision和recall\n","for category in categories:\n","    # 初始化统计数据\n","    TP = 0\n","    FP = 0\n","    FN = 0\n","\n","    # 遍历图片\n","    for image_name in os.listdir(image_folder_path):\n","        if image_name.endswith(\".png\"):\n","            image_path = os.path.join(image_folder_path, image_name)\n","\n","            # 预处理图片\n","            image = processor(images=(Image.open(image_path)), return_tensors=\"pt\").to(device)\n","\n","            # 准备文本\n","            text_labels = [category]\n","            # text = clip.tokenize(list(categories.keys()) + [\"others\"]).to(device)\n","            text = text_tokenizer(text_labels, return_tensors='pt', padding=True)['input_ids'].to(device)\n","\n","            # 进行预测\n","            similarity = cal_similarity(image, text)\n","\n","            # 使用阈值判断类别\n","            is_positive_prediction = similarity[0] > threshold\n","            predicted_category = category if is_positive_prediction else \"others\"\n","\n","            # 判断真实类别\n","            actual_category = category if category in image_name else \"others\"\n","\n","            # 更新统计数据\n","            if predicted_category == actual_category and actual_category == category:\n","                TP += 1\n","            elif predicted_category == category and actual_category == \"others\":\n","                FP += 1\n","            elif actual_category == category and predicted_category == \"others\":\n","                FN += 1\n","\n","    # 计算Precision和Recall\n","    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n","    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","\n","    print(f\"Category: {category}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n","    total_precision += precision\n","    total_recall += recall\n","    total_f1 += f1_score\n","\n","# 计算并打印平均Precision和Recall\n","average_precision = total_precision / len(categories)\n","average_recall = total_recall / len(categories)\n","average_f1 = total_f1 / len(categories)\n","\n","print(f\"Average Precision: {average_precision:.4f}, Average Recall: {average_recall:.4f}, Average F1: {average_f1:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOugK2a23Eub","executionInfo":{"status":"ok","timestamp":1710236639138,"user_tz":-480,"elapsed":639822,"user":{"displayName":"Thomasine Kaczka","userId":"06732724743998191518"}},"outputId":"c353b7d2-379a-4e76-80f5-58162b3e5694"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Category: 宠物猫, Precision: 0.9706, Recall: 0.9900, F1 Score: 0.9802\n","Category: 番茄, Precision: 1.0000, Recall: 0.9600, F1 Score: 0.9796\n","Category: 剪纸, Precision: 1.0000, Recall: 0.9600, F1 Score: 0.9796\n","Category: 电脑, Precision: 1.0000, Recall: 0.6250, F1 Score: 0.7692\n","Category: 饺子, Precision: 0.9213, Recall: 0.9950, F1 Score: 0.9567\n","Average Precision: 0.9784, Average Recall: 0.9060, Average F1: 0.9331\n"]}]},{"cell_type":"markdown","source":["中英文CLIP类别判断函数"],"metadata":{"id":"66R_xJQYJell"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGVVfIEXOTi7"},"outputs":[],"source":["import os\n","import torch\n","import clip\n","import shutil\n","from PIL import Image\n","from transformers import BertTokenizer, BertForSequenceClassification, CLIPProcessor, CLIPModel\n","from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n","\n","# 设置设备\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model_1, processor_1 = clip.load(\"ViT-B/32\", device=device)\n","\n","text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\")\n","text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\").eval().to(device)\n","model_2 = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n","processor_2 = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", device=device)\n","\n","def run_english_clip_model(image_name, category):\n","    image_path = os.path.join(image_folder_path, image_name)\n","    image = processor_1(Image.open(image_path)).unsqueeze(0).to(device)\n","    # text = clip.tokenize([category, \"others\"]).to(device)\n","    text = clip.tokenize([category]).to(device)\n","\n","    with torch.no_grad():\n","        image_features = model_1.encode_image(image)\n","        text_features = model_1.encode_text(text)\n","\n","        image_features /= image_features.norm(dim=-1, keepdim=True)\n","        text_features /= text_features.norm(dim=-1, keepdim=True)\n","\n","        similarity = image_features @ text_features.T\n","\n","        threshold = 0.24\n","        is_positive_prediction = similarity[0] > threshold\n","\n","    return is_positive_prediction\n","\n","\n","def run_chinese_clip_model(image_name, category):\n","    image_path = os.path.join(image_folder_path, image_name)\n","    image = processor_2(images=(Image.open(image_path)), return_tensors=\"pt\").to(device)\n","    # text = text_tokenizer([category, \"其他\"], return_tensors='pt', padding=True)['input_ids'].to(device)\n","    text = text_tokenizer([category], return_tensors='pt', padding=True)['input_ids'].to(device)\n","\n","    with torch.no_grad():\n","        image_features = model_2.get_image_features(**image)\n","        text_features = text_encoder(text).logits\n","        # 归一化\n","        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n","        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n","        # 计算余弦相似度\n","        logit_scale = model_2.logit_scale.exp()\n","        logits_per_image = logit_scale * image_features @ text_features.t()\n","        # probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","        similarity = image_features @ text_features.t()\n","\n","        threshold = 0.1\n","        is_positive_prediction = similarity[0] > threshold\n","\n","    return is_positive_prediction"]},{"cell_type":"markdown","source":["中英文CLIP结果取并集，并复制分类结果"],"metadata":{"id":"HF7ljhT3JvHP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS5A0NynNdNJ","executionInfo":{"status":"ok","timestamp":1710382652072,"user_tz":-480,"elapsed":872738,"user":{"displayName":"Thomasine Kaczka","userId":"06732724743998191518"}},"outputId":"16905f1f-0d30-4c8a-9718-f34d2727c00f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Category: pet cat, Precision: 0.9390, Recall: 1.0000, F1 Score: 0.9685\n","Category: tomato, Precision: 0.7082, Recall: 0.9950, F1 Score: 0.8274\n","Category: paper-cut, Precision: 0.8615, Recall: 0.9950, F1 Score: 0.9234\n","Category: computer, Precision: 0.9635, Recall: 0.9250, F1 Score: 0.9439\n","Category: dumpling, Precision: 0.4246, Recall: 1.0000, F1 Score: 0.5961\n","Average Precision: 0.7794, Average Recall: 0.9830, Average F1: 0.8519\n"]}],"source":["categories = {\n","    \"pet cat\": \"宠物猫\",\n","    \"tomato\": \"番茄\",\n","    \"paper-cut\": \"剪纸\",\n","    \"computer\": \"电脑\",\n","    \"dumpling\": \"饺子\"\n","}\n","\n","image_folder_path = \"/content/drive/MyDrive/picture_data\"\n","target_root_folder = \"/content/drive/MyDrive/target_data3/\"\n","\n","# 初始化统计数据\n","total_precision = 0\n","total_recall = 0\n","total_f1 = 0\n","\n","for category in categories.keys():\n","    # 确保每个类别的目标文件夹存在\n","    target_folder = os.path.join(target_root_folder, category)\n","    os.makedirs(target_folder, exist_ok=True)\n","\n","for category, keyword in categories.items():\n","    TP = 0\n","    FP = 0\n","    FN = 0\n","\n","    for image_name in os.listdir(image_folder_path):\n","        if image_name.endswith(\".png\"):\n","            # 运行英文CLIP模型\n","            is_positive_english = run_english_clip_model(image_name, category)\n","            # 运行中文CLIP模型\n","            is_positive_chinese = run_chinese_clip_model(image_name, keyword)\n","\n","            # 判断是否为正样本（英文和中文结果的并集）\n","            is_positive = is_positive_english or is_positive_chinese\n","\n","            image_path = os.path.join(image_folder_path, image_name)\n","            if is_positive:\n","                target_folder = os.path.join(target_root_folder, category)\n","                shutil.copy(image_path, target_folder)\n","\n","    # 获取分类后的图片路径\n","    target_folder = os.path.join(target_root_folder, category)\n","    classified_images = os.listdir(target_folder)\n","\n","    for image_name in classified_images:\n","        if image_name.endswith(\".png\"):\n","            # 判断真实类别\n","            actual_category = category if keyword in image_name else \"其他\"\n","\n","            # 更新统计数据\n","            if actual_category == category:\n","                TP += 1\n","            else:\n","                FP += 1\n","\n","    # 计算并打印当前类别的Precision、Recall\n","    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n","    recall = TP / 200  # 固定正样本总数为200\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    print(f\"Category: {category}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n","\n","    # 更新总体统计数据\n","    total_precision += precision\n","    total_recall += recall\n","    total_f1 += f1_score\n","\n","# 计算并打印平均Precision、Recall和F1分数\n","average_precision = total_precision / len(categories)\n","average_recall = total_recall / len(categories)\n","average_f1 = total_f1 / len(categories)\n","print(f\"Average Precision: {average_precision:.4f}, Average Recall: {average_recall:.4f}, Average F1: {average_f1:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"mount_file_id":"1ys6d9h7WcyQPrBWuROLdewS3y2EWBJ7P","authorship_tag":"ABX9TyOmOWZlaBs7gEYdq6PuYnw/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}